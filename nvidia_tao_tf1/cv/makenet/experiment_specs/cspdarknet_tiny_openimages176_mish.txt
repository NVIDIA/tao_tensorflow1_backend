model_config {
  # Model Architecture can be chosen from:
  # ['resnet', 'vgg', 'googlenet', 'alexnet']
  arch: "cspdarknet_tiny"
  # for resnet --> n_layers can be [10, 18, 50]
  # for vgg --> n_layers can be [16, 19]
  use_bias: False
  retain_head: True
  use_batch_norm: True
  activation {
    activation_type: "mish"
  }
  resize_interpolation_method: BICUBIC
  # if you want to use the pretrained model,
  # image size should be "3,224,224"
  # otherwise, it can be "3, X, Y", where X,Y >= 16
  input_image_size: "3,224,224"
}
train_config {
  preprocess_mode: "caffe"
  train_dataset_path: "/data/zhimengf/tlt-experiments/data/openimages176/train"
  val_dataset_path: "/data/zhimengf/tlt-experiments/data/openimages176/val"
  # Only ['sgd', 'adam'] are supported for optimizer
  optimizer {
    sgd {
    lr: 0.01
    decay: 0.0
    momentum: 0.9
    nesterov: False
  }
  }
  batch_size_per_gpu: 64
  n_epochs: 100
  # Number of CPU cores for loading data
  n_workers: 16
  # regularizer
  reg_config {
    # regularizer type can be "L1", "L2" or "None".
    type: "L2"
    # if the type is not "None",
    # scope can be either "Conv2D" or "Dense" or both.
    scope: "Conv2D,Dense"
    # 0 < weight decay < 1
    weight_decay: 5e-5
  }
  lr_config {
    cosine {
      learning_rate: 0.05
      min_lr_ratio: 0.001
    }
  }
  enable_random_crop: True
  enable_center_crop: True
  enable_color_augmentation: True
  mixup_alpha: 0.2
  label_smoothing: 0.1
}
eval_config {
  eval_dataset_path: "/data/zhimengf/tlt-experiments/data/openimages176/val"
  model_path: "/data/zhimengf/tlt-experiments/weights/cspdarknet_tiny_001.tlt"
  top_k: 1
  batch_size: 32
  n_workers: 8
  enable_center_crop: True
}