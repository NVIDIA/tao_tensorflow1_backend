model_config {
  # Model Architecture can be chosen from:
  # ['resnet', 'vgg', 'googlenet', 'alexnet']
  arch: "vgg"
  # for resnet --> n_layers can be [10, 18, 50]
  # for vgg --> n_layers can be [16, 19]
  n_layers: 16
  use_batch_norm: True
  use_bias: False
  use_pooling: True
  dropout: 0.0
  retain_head: True
  resize_interpolation_method: BICUBIC
  # if you want to use the pretrained model,
  # image size should be "3,224,224"
  # otherwise, it can be "3, X, Y", where X,Y >= 16
  input_image_size: "3,224,224"
}
train_config {
  train_dataset_path: "/raid/openimages176/train"
  val_dataset_path: "/raid/openimages176/val"
  # Only ['sgd', 'adam'] are supported for optimizer
  optimizer {
    sgd {
    lr: 0.01
    decay: 0.0
    momentum: 0.9
    nesterov: False
  }
}
  batch_size_per_gpu: 64
  n_epochs: 80
  # Number of CPU cores for loading data
  n_workers: 16
  # regularizer
  reg_config {
    # regularizer type can be "L1", "L2" or "None".
    type: "L2"
    # if the type is not "None",
    # scope can be either "Conv2D" or "Dense" or both.
    scope: "Conv2D,Dense"
    # 0 < weight decay < 1
    weight_decay: 0.00005
  }
  # learning_rate
  lr_config {
    soft_anneal {
      learning_rate: 0.05
      soft_start: 0.056
      annealing_points: 0.3
      annealing_points: 0.6
      annealing_points: 0.8
      annealing_divider: 10
    }
  }
  enable_random_crop: True
  enable_center_crop: True
  enable_color_augmentation: True
}
eval_config {
  eval_dataset_path: "/raid/openimages176/val"
  model_path: "/workspace/tlt-experiments/classification/output/weights/vgg16_80.tlt"
  top_k: 1
  batch_size: 32
  n_workers: 8
  enable_center_crop: True
}
