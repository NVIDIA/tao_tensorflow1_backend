# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: nvidia_tao_tf1/cv/faster_rcnn/proto/trt_config.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='nvidia_tao_tf1/cv/faster_rcnn/proto/trt_config.proto',
  package='',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=_b('\n4nvidia_tao_tf1/cv/faster_rcnn/proto/trt_config.proto\"\"\n\x0cTrtInference\x12\x12\n\ntrt_engine\x18\x01 \x01(\tb\x06proto3')
)




_TRTINFERENCE = _descriptor.Descriptor(
  name='TrtInference',
  full_name='TrtInference',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='trt_engine', full_name='TrtInference.trt_engine', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=56,
  serialized_end=90,
)

DESCRIPTOR.message_types_by_name['TrtInference'] = _TRTINFERENCE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

TrtInference = _reflection.GeneratedProtocolMessageType('TrtInference', (_message.Message,), dict(
  DESCRIPTOR = _TRTINFERENCE,
  __module__ = 'nvidia_tao_tf1.cv.faster_rcnn.proto.trt_config_pb2'
  # @@protoc_insertion_point(class_scope:TrtInference)
  ))
_sym_db.RegisterMessage(TrtInference)


# @@protoc_insertion_point(module_scope)
